{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Double Q-Networks \n",
    "\n",
    "### Syed Zain Raza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "myEnvironment = gameEnv(partial=False, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Q Network\n",
    "\n",
    "#### 1. Gets a frame , flattens and reshape it.\n",
    "#### 2. Process it through multiple convolutional layers\n",
    "#### 3. Split output of convolutional layer into Value and Advantage\n",
    "#### 4. Combine them again to get final Q value\n",
    "#### 5. Calculate loss using sum of square difference between predicted and targeted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "        \n",
    "class Q_Network():\n",
    "    \n",
    "    def __init__(self, hsize):\n",
    "        self.scalarInput = tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        \n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1, 84, 84, 3])\n",
    "        \n",
    "        self.conv1 = slim.conv2d(inputs = self.imageIn, num_outputs = 32, kernel_size = [8, 8], stride = [4, 4], padding = 'VALID', biases_initializer = None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv2 = slim.conv2d(inputs = self.conv1, num_outputs = 64, kernel_size = [4, 4], stride = [2, 2], padding = 'VALID', biases_initializer = None)\n",
    "        \n",
    "        self.conv3 = slim.conv2d(inputs = self.conv2, num_outputs = 64, kernel_size = [3, 3], stride = [1, 1], padding = 'VALID', biases_initializer = None)\n",
    "        \n",
    "        self.conv4 = slim.conv2d(inputs = self.conv3, num_outputs = h_size, kernel_size = [7, 7], stride = [1, 1], padding = 'VALID', biases_initializer = None)\n",
    "        \n",
    "        \n",
    "        #\n",
    "        self.m_advantage, self.m_value = tf.split(self.conv4, 2, 3)\n",
    "        \n",
    "        self.advantageFlat = slim.flatten(self.m_advantage)\n",
    "        \n",
    "        self.valueFlat = slim.flatten(self.m_value)\n",
    "        \n",
    "        xa = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        self.m1_advantage = tf.Variable(xa([hsize//2, myEnvironment.actions]))\n",
    "        \n",
    "        self.m1_value = tf.Variable(xa([hsize//2, 1]))\n",
    "\n",
    "        self.f_Advantage = tf.matmul(self.advantageFlat, self.m1_advantage)\n",
    "        \n",
    "        self.f_Value = tf.matmul(self.valueFlat, self.m1_value)\n",
    "        \n",
    "        #\n",
    "        self.finalQVal = self.f_Value +  tf.subtract(self.f_Advantage, tf.reduce_mean(self.f_Advantage, axis = 1, keep_dims = True))\n",
    "        \n",
    "        self.prd = tf.argmax(self.finalQVal, 1)\n",
    "        \n",
    "        self.m_Target = tf.placeholder(shape=[None], dtype = tf.float32)\n",
    "        \n",
    "        self.m_Actions = tf.placeholder(shape=[None], dtype = tf.int32)\n",
    "        \n",
    "        self.one_Actions = tf.one_hot(self.m_Actions, myEnvironment.actions, dtype = tf.float32)\n",
    "        \n",
    "        self.m_Q = tf.reduce_sum(tf.multiply(self.finalQVal, self.one_Actions), axis = 1)\n",
    "        \n",
    "        self.td_Error = tf.square(self.m_Target - self.m_Q)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(self.td_Error)\n",
    "        \n",
    "        self.m_Trainer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "        \n",
    "        self.model_Updated = self.m_Trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay\n",
    "#### This block of code uses the concept of episode replay to store experiences and then use them to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class exp_Replay():\n",
    "    def __init__(self, sizeof_Buffer = 50000):\n",
    "        self.m_Buffer = []\n",
    "        self.sizeofBuffer = sizeof_Buffer\n",
    "        \n",
    "    def m_Add(self, m_Exp):\n",
    "        if len(self.m_Buffer) + len(m_Exp) >= self.sizeofBuffer:\n",
    "            self.m_Buffer[0:(len(m_Exp) + len(self.m_Buffer) )-  self.sizeofBuffer] = []\n",
    "            \n",
    "        self.m_Buffer.extend(m_Exp)\n",
    "        \n",
    "        \n",
    "    def m_Sample(self, size):\n",
    "        return np.reshape(np.array(random.sample(self.m_Buffer, size)), [size, 5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def m_statesProcess(m_States):\n",
    "    return np.reshape(m_States, [21168])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def m_targetUpdate(tfVar, tau):\n",
    "    m_totalVar = len(tfVar)\n",
    "    \n",
    "    m_holder = []\n",
    "    \n",
    "    for i , var in enumerate(tfVar[0:m_totalVar//2]):\n",
    "        m_holder.append(tfVar[i + m_totalVar//2].assign((var.value()*tau) + ((1 - tau) * tfVar[i + m_totalVar//2].value())))\n",
    "    return m_holder\n",
    "\n",
    "def m_targetUpdate1(m_holder, sess):\n",
    "    for j in m_holder:\n",
    "        sess.run(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Initialization for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m_BatchSize = 32\n",
    "\n",
    "m_updateFreq = 4\n",
    "\n",
    "m_discount = 0.99\n",
    "\n",
    "m_startR = 1\n",
    "\n",
    "m_endR = 0.1\n",
    "\n",
    "m_stepsT = 10000\n",
    "\n",
    "m_NumEp = 10000\n",
    "\n",
    "m_preTrain = 10000\n",
    "\n",
    "m_maxEP = 50\n",
    "\n",
    "m_loadModel = False\n",
    "\n",
    "path = \"./dqn\"\n",
    "\n",
    "h_size = 512\n",
    "\n",
    "tau = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "500 0.0 1\n",
      "1000 0.0 1\n",
      "1500 0.0 1\n",
      "2000 0.0 1\n",
      "2500 0.0 1\n",
      "3000 0.0 1\n",
      "3500 0.0 1\n",
      "4000 0.0 1\n",
      "4500 0.0 1\n",
      "5000 0.0 1\n",
      "5500 0.0 1\n",
      "6000 0.0 1\n",
      "6500 0.0 1\n",
      "7000 0.0 1\n",
      "7500 0.0 1\n",
      "8000 0.0 1\n",
      "8500 0.0 1\n",
      "9000 0.0 1\n",
      "9500 0.0 1\n",
      "10000 0.0 1\n",
      "10500 1.9 0.9549999999999828\n",
      "11000 2.6 0.9099999999999655\n",
      "11500 0.6 0.8649999999999483\n",
      "12000 2.7 0.819999999999931\n",
      "12500 0.8 0.7749999999999138\n",
      "13000 3.0 0.7299999999998965\n",
      "13500 3.3 0.6849999999998793\n",
      "14000 1.2 0.639999999999862\n",
      "14500 2.5 0.5949999999998448\n",
      "15000 1.9 0.5499999999998275\n",
      "15500 0.6 0.5049999999998103\n",
      "16000 2.3 0.4599999999998177\n",
      "16500 3.1 0.41499999999982823\n",
      "17000 1.3 0.36999999999983874\n",
      "17500 1.8 0.32499999999984924\n",
      "18000 1.7 0.27999999999985975\n",
      "18500 2.6 0.23499999999986562\n",
      "19000 1.4 0.18999999999986225\n",
      "19500 1.4 0.14499999999985888\n",
      "20000 1.7 0.09999999999985551\n",
      "20500 2.0 0.09999999999985551\n",
      "21000 0.7 0.09999999999985551\n",
      "21500 0.3 0.09999999999985551\n",
      "22000 2.3 0.09999999999985551\n",
      "22500 1.3 0.09999999999985551\n",
      "23000 1.0 0.09999999999985551\n",
      "23500 2.0 0.09999999999985551\n",
      "24000 3.1 0.09999999999985551\n",
      "24500 2.3 0.09999999999985551\n",
      "25000 1.3 0.09999999999985551\n",
      "25500 3.1 0.09999999999985551\n",
      "26000 4.5 0.09999999999985551\n",
      "26500 3.6 0.09999999999985551\n",
      "27000 3.8 0.09999999999985551\n",
      "27500 5.3 0.09999999999985551\n",
      "28000 1.9 0.09999999999985551\n",
      "28500 4.0 0.09999999999985551\n",
      "29000 3.7 0.09999999999985551\n",
      "29500 3.4 0.09999999999985551\n",
      "30000 4.9 0.09999999999985551\n",
      "30500 3.5 0.09999999999985551\n",
      "31000 4.3 0.09999999999985551\n",
      "31500 2.9 0.09999999999985551\n",
      "32000 4.0 0.09999999999985551\n",
      "32500 4.1 0.09999999999985551\n",
      "33000 7.2 0.09999999999985551\n",
      "33500 6.9 0.09999999999985551\n",
      "34000 2.8 0.09999999999985551\n",
      "34500 5.1 0.09999999999985551\n",
      "35000 5.1 0.09999999999985551\n",
      "35500 7.1 0.09999999999985551\n",
      "36000 7.6 0.09999999999985551\n",
      "36500 7.0 0.09999999999985551\n",
      "37000 11.8 0.09999999999985551\n",
      "37500 8.7 0.09999999999985551\n",
      "38000 6.7 0.09999999999985551\n",
      "38500 6.6 0.09999999999985551\n",
      "39000 10.6 0.09999999999985551\n",
      "39500 11.0 0.09999999999985551\n",
      "40000 7.3 0.09999999999985551\n",
      "40500 9.6 0.09999999999985551\n",
      "41000 7.4 0.09999999999985551\n",
      "41500 10.7 0.09999999999985551\n",
      "42000 10.8 0.09999999999985551\n",
      "42500 16.0 0.09999999999985551\n",
      "43000 11.8 0.09999999999985551\n",
      "43500 13.3 0.09999999999985551\n",
      "44000 13.7 0.09999999999985551\n",
      "44500 13.0 0.09999999999985551\n",
      "45000 14.8 0.09999999999985551\n",
      "45500 13.6 0.09999999999985551\n",
      "46000 14.1 0.09999999999985551\n",
      "46500 16.4 0.09999999999985551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-eb1be303259b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                     _ = sess.run(m_QNetwork.model_Updated, \\\n\u001b[1;32m---> 98\u001b[1;33m                         feed_dict={m_QNetwork.scalarInput:np.vstack(m_TrainBatch[:,0]),m_QNetwork.m_Target:m_Target, m_QNetwork.m_Actions:m_TrainBatch[:,1]})\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                     \u001b[0mm_targetUpdate1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_targetOps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "m_QNetwork = Q_Network(h_size)\n",
    "\n",
    "m_targetQNetwork = Q_Network(h_size)\n",
    "\n",
    "m_init = tf.global_variables_initializer()\n",
    "\n",
    "m_Save = tf.train.Saver()\n",
    "\n",
    "m_Trainables = tf.trainable_variables()\n",
    "\n",
    "m_targetOps = m_targetUpdate(m_Trainables, tau)\n",
    "\n",
    "m_Buffer = exp_Replay()\n",
    "\n",
    "#\n",
    "\n",
    "    \n",
    "m_E = m_startR\n",
    "\n",
    "m_Drop = (m_startR - m_endR) / m_stepsT\n",
    "\n",
    "m_JList = []\n",
    "\n",
    "m_RewardList = []\n",
    "\n",
    "m_stepsTotal = 0\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "    \n",
    "#\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(m_init)\n",
    "    if m_loadModel == True:\n",
    "        print('Load the Model')\n",
    "        m_checkpoints = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, m_checkpoints.model_checkpoint_path)\n",
    "    for i in range(m_NumEp):\n",
    "        m_EPBuffer = exp_Replay()\n",
    "        \n",
    "        m_S = myEnvironment.reset()\n",
    "        \n",
    "        m_S = m_statesProcess(m_S)\n",
    "        \n",
    "        m_d = False\n",
    "        \n",
    "        m_rewardAll = 0\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "\n",
    "        while j < m_maxEP:\n",
    "            j+=1 \n",
    "            if np.random.rand(1) < m_E or m_stepsTotal < m_preTrain:\n",
    "                m_A = np.random.randint(0, 4)\n",
    "            else:\n",
    "                m_A = sess.run(m_QNetwork.prd, feed_dict={m_QNetwork.scalarInput:[m_S]})[0]\n",
    "                \n",
    "            m_S1, m_R, m_D = myEnvironment.step(m_A)\n",
    "            \n",
    "            m_S1 = m_statesProcess(m_S1)\n",
    "            \n",
    "            m_stepsTotal += 1\n",
    "            \n",
    "            m_EPBuffer.m_Add(np.reshape(np.array([m_S, m_A, m_R, m_S1, m_D]),[1,5]))\n",
    "            \n",
    "            \n",
    "            if m_stepsTotal > m_preTrain:\n",
    "                if m_E > m_endR:\n",
    "                    m_E -= m_Drop\n",
    "                    \n",
    "                if m_stepsTotal % (m_updateFreq) == 0:\n",
    "                    m_TrainBatch = m_Buffer.m_Sample(m_BatchSize)\n",
    "                    \n",
    "                    m_Q1 = sess.run(m_QNetwork.prd, feed_dict={m_QNetwork.scalarInput:np.vstack(m_TrainBatch[:,3])})\n",
    "                    \n",
    "                    m_Q2 = sess.run(m_targetQNetwork.finalQVal, feed_dict={m_targetQNetwork.scalarInput:np.vstack(m_TrainBatch[:,3])})\n",
    "                    \n",
    "                    m_EndMult = -(m_TrainBatch[:,4] -1)\n",
    "                    \n",
    "                    m_DoubleQ = m_Q2[range(m_BatchSize), m_Q1]\n",
    "                    \n",
    "                    m_Target = m_TrainBatch[:,2] + (m_discount * m_DoubleQ * m_EndMult)\n",
    "                    \n",
    "                    _ = sess.run(m_QNetwork.model_Updated, \\\n",
    "                        feed_dict={m_QNetwork.scalarInput:np.vstack(m_TrainBatch[:,0]),m_QNetwork.m_Target:m_Target, m_QNetwork.m_Actions:m_TrainBatch[:,1]})\n",
    "                    \n",
    "                    m_targetUpdate1(m_targetOps,sess) \n",
    "                    \n",
    "                m_rewardAll += m_R\n",
    "                \n",
    "                m_S = m_S1 \n",
    "                \n",
    "                if m_D ==True:\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        m_Buffer.m_Add(m_EPBuffer.m_Buffer)\n",
    "        \n",
    "        m_JList.append(j)\n",
    "        \n",
    "        m_RewardList.append(m_rewardAll)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            m_Save.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "            \n",
    "        if len(m_RewardList) % 10 == 0:\n",
    "            print(m_stepsTotal,np.mean(m_RewardList[-10:]), m_E)\n",
    "            \n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "    \n",
    "print(\"Percent of succesful episodes: \" + str(sum(m_RewardList)/m_NumEp) + \"%\")\n",
    "    \n",
    "        \n",
    "            \n",
    "                    \n",
    "            \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Reward over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2100c778b38>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "m_rmat = np.resize(np.array(m_RewardList),[len(m_RewardList)//100,100])\n",
    "\n",
    "m_rewardMean = np.average(m_rmat,1)\n",
    "\n",
    "plt.plot(m_rewardMean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
